{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(precision=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    \n",
    "# Aprendizagem de Máquina (ES456/2018-2)\n",
    "## Lista de exercícios 1\n",
    "### 2018-09-22\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Utilizando a base de dados Iris, disponível no link abaixo, e a linguagem de programação de sua preferência, calcule para cada classe:\n",
    "<br />\n",
    "a) O vetor médio\n",
    "<br />\n",
    "b) O vetor de desvio padrão para cada característica da base de dados\n",
    "<br />\n",
    "c) O vetor máximo para cada característica da base de dados\n",
    "<br />\n",
    "d) O vetor mínimo para cada característica da base de dados\n",
    "<br />\n",
    "e) A matriz de dispersão\n",
    "<br />\n",
    "f) A matriz de covariância\n",
    "<br />\n",
    "g) A matriz de correlação\n",
    "<br />\n",
    "h) As duas componentes principais de maior magnitude dos dados\n",
    "<br />\n",
    "i) A projeção dos dados nas duas maiores componentes principais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris-setosa -> 0\n",
    "# iris-versicolor -> 1\n",
    "# iris-virginica -> 2\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "iris_features = iris.data[:, :4]\n",
    "iris_target = iris.target\n",
    "classes_number = len(set(iris_target))\n",
    "\n",
    "def class_name(class_):\n",
    "    if class_ == 0: return 'iris-setosa'\n",
    "    if class_ == 1: return 'iris-versicolor'\n",
    "    if class_ == 2: return 'iris-virginica'\n",
    "\n",
    "def print_answer(question, answer):\n",
    "    print(f\"Resposta {question}:\\n{answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1a)\n",
      "iris-setosa\n",
      "[5.005999999999999, 3.4180000000000006, 1.464, 0.2439999999999999]\n",
      "iris-versicolor\n",
      "[5.936, 2.7700000000000005, 4.26, 1.3259999999999998]\n",
      "iris-virginica\n",
      "[6.587999999999998, 2.9739999999999998, 5.552, 2.026]\n"
     ]
    }
   ],
   "source": [
    "def mean(array):\n",
    "    return sum(array)/len(array)\n",
    "\n",
    "def column_vec(func, matrix):\n",
    "    return [func(matrix[:,i]) for i in range(len(matrix[0]))]\n",
    "\n",
    "print('1a)')\n",
    "for i in range(classes_number):\n",
    "    print(class_name(i))\n",
    "    print(column_vec(mean, iris_features[np.where(iris_target == i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1b)\n",
      "iris-setosa\n",
      "[0.3524896872134512, 0.38102439795469095, 0.1735111594364455, 0.10720950308167837]\n",
      "iris-versicolor\n",
      "[0.5161711470638635, 0.3137983233784114, 0.46991097723995806, 0.197752680004544]\n",
      "iris-virginica\n",
      "[0.635879593274432, 0.3224966381726376, 0.5518946956639835, 0.27465005563666733]\n"
     ]
    }
   ],
   "source": [
    "def standard_deviation(array):\n",
    "    if len(array) == 0: return 0.0\n",
    "    _mean = mean(array)\n",
    "    sq_diff_sum = sum([(number-_mean)**2 for number in array])\n",
    "    return (sq_diff_sum/(len(array)-1))**0.5\n",
    "\n",
    "print('1b)')\n",
    "for i in range(classes_number):\n",
    "    print(class_name(i))\n",
    "    print(column_vec(standard_deviation, iris_features[np.where(iris_target == i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1c)\n",
      "iris-setosa\n",
      "[5.8, 4.4, 1.9, 0.6]\n",
      "iris-versicolor\n",
      "[7.0, 3.4, 5.1, 1.8]\n",
      "iris-virginica\n",
      "[7.9, 3.8, 6.9, 2.5]\n"
     ]
    }
   ],
   "source": [
    "print('1c)')\n",
    "for i in range(classes_number):\n",
    "    print(class_name(i))\n",
    "    print(column_vec(max, iris_features[np.where(iris_target == i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1d)\n",
      "iris-setosa\n",
      "[4.3, 2.3, 1.0, 0.1]\n",
      "iris-versicolor\n",
      "[4.9, 2.0, 3.0, 1.0]\n",
      "iris-virginica\n",
      "[4.9, 2.2, 4.5, 1.4]\n"
     ]
    }
   ],
   "source": [
    "print('1d)')\n",
    "for i in range(classes_number):\n",
    "    print(class_name(i))\n",
    "    print(column_vec(min, iris_features[np.where(iris_target == i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e)\n",
      "iris-setosa\n",
      "[[6.0882 4.9146 0.7908 0.5168]\n",
      " [4.9146 7.1138 0.5724 0.5604]\n",
      " [0.7908 0.5724 1.4752 0.2792]\n",
      " [0.5168 0.5604 0.2792 0.5632]]\n",
      "iris-versicolor\n",
      "[[13.0552  4.174   8.962   2.7332]\n",
      " [ 4.174   4.825   4.05    2.019 ]\n",
      " [ 8.962   4.05   10.82    3.582 ]\n",
      " [ 2.7332  2.019   3.582   1.9162]]\n",
      "iris-virginica\n",
      "[[19.8128  4.5944 14.8612  2.4056]\n",
      " [ 4.5944  5.0962  3.4976  2.3338]\n",
      " [14.8612  3.4976 14.9248  2.3924]\n",
      " [ 2.4056  2.3338  2.3924  3.6962]]\n"
     ]
    }
   ],
   "source": [
    "def dispersion_matrix(matrix):\n",
    "    return (matrix - column_vec(mean, matrix)).T.dot((matrix - column_vec(mean, matrix)))\n",
    "\n",
    "print('1e)')\n",
    "for i in range(classes_number):\n",
    "    print(class_name(i))\n",
    "    print(dispersion_matrix(iris_features[np.where(iris_target == i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1f)\n",
      "iris-setosa\n",
      "[[0.1242 0.1003 0.0161 0.0105]\n",
      " [0.1003 0.1452 0.0117 0.0114]\n",
      " [0.0161 0.0117 0.0301 0.0057]\n",
      " [0.0105 0.0114 0.0057 0.0115]]\n",
      "iris-versicolor\n",
      "[[0.2664 0.0852 0.1829 0.0558]\n",
      " [0.0852 0.0985 0.0827 0.0412]\n",
      " [0.1829 0.0827 0.2208 0.0731]\n",
      " [0.0558 0.0412 0.0731 0.0391]]\n",
      "iris-virginica\n",
      "[[0.4043 0.0938 0.3033 0.0491]\n",
      " [0.0938 0.104  0.0714 0.0476]\n",
      " [0.3033 0.0714 0.3046 0.0488]\n",
      " [0.0491 0.0476 0.0488 0.0754]]\n"
     ]
    }
   ],
   "source": [
    "def covariance(x1, x2):\n",
    "    return mean(x1*x2) - mean(x1)*mean(x2)\n",
    "\n",
    "def cov_matrix(matrix):\n",
    "    return dispersion_matrix(matrix)/(len(matrix[:, 0]) - 1)\n",
    "\n",
    "print('1f)')\n",
    "for i in range(classes_number):\n",
    "    print(class_name(i))\n",
    "    print((cov_matrix(iris_features[np.where(iris_target == i)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative method to calculate dispersion matrix\n",
    "def dispersion_matrix2(matrix):\n",
    "    return cov_matrix(matrix)*(len(matrix[:, 0])-1)\n",
    "\n",
    "# alternative method to calculate covariance matrix\n",
    "def covariance(x1, x2):\n",
    "    return mean(x1*x2) - mean(x1)*mean(x2)\n",
    "\n",
    "def cov_matrix2(matrix):\n",
    "    columns_num = matrix.shape[1]\n",
    "    result = np.zeros((columns_num, columns_num))\n",
    "    \n",
    "    for i in range(columns_num):\n",
    "        for j in range(i, columns_num):\n",
    "            result[i][j] = covariance(matrix[:,i], matrix[:,j])\n",
    "            result[j][i] = result[i][j]\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1g)\n",
      "iris-setosa\n",
      "[[1.     0.7468 0.2639 0.2791]\n",
      " [0.7468 1.     0.1767 0.28  ]\n",
      " [0.2639 0.1767 1.     0.3063]\n",
      " [0.2791 0.28   0.3063 1.    ]]\n",
      "iris-versicolor\n",
      "[[1.     0.5259 0.754  0.5465]\n",
      " [0.5259 1.     0.5605 0.664 ]\n",
      " [0.754  0.5605 1.     0.7867]\n",
      " [0.5465 0.664  0.7867 1.    ]]\n",
      "iris-virginica\n",
      "[[1.     0.4572 0.8642 0.2811]\n",
      " [0.4572 1.     0.401  0.5377]\n",
      " [0.8642 0.401  1.     0.3221]\n",
      " [0.2811 0.5377 0.3221 1.    ]]\n"
     ]
    }
   ],
   "source": [
    "def inverse_std_dev_matrix(matrix):\n",
    "    columns_num = matrix.shape[1]\n",
    "    result = np.zeros((columns_num, columns_num))\n",
    "    \n",
    "    for i in range(columns_num):\n",
    "        result[i][i] = 1/(standard_deviation(matrix[:,i])**2)\n",
    "        for j in range(i+1, columns_num):\n",
    "            result[i][j] = 1/(standard_deviation(matrix[:,i]) * standard_deviation(matrix[:,j]))\n",
    "            result[j][i] = result[i][j]\n",
    "    \n",
    "    return result\n",
    "            \n",
    "def cor_matrix(matrix):\n",
    "    return cov_matrix(matrix) * inverse_std_dev_matrix(matrix)\n",
    "\n",
    "print('1g)')\n",
    "for i in range(classes_number):\n",
    "    print(class_name(i))\n",
    "    print(cor_matrix(iris_features[np.where(iris_target == i)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resposta 1h):\n",
      "[[ 0.3616 -0.6565]\n",
      " [-0.0823 -0.7297]\n",
      " [ 0.8566  0.1758]\n",
      " [ 0.3588  0.0747]]\n"
     ]
    }
   ],
   "source": [
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix(iris_features))\n",
    "\n",
    "print_answer('1h)', eigenvectors[:, 0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resposta 1i):\n",
      "[[ 2.8271 -5.6413]\n",
      " [ 2.796  -5.1452]\n",
      " [ 2.6215 -5.1774]\n",
      " [ 2.7649 -5.0036]\n",
      " [ 2.7828 -5.6486]\n",
      " [ 3.2314 -6.0625]\n",
      " [ 2.6905 -5.2326]\n",
      " [ 2.8849 -5.4851]\n",
      " [ 2.6234 -4.7439]\n",
      " [ 2.8375 -5.208 ]\n",
      " [ 3.0048 -5.9667]\n",
      " [ 2.8982 -5.3362]\n",
      " [ 2.7239 -5.087 ]\n",
      " [ 2.2861 -4.8114]\n",
      " [ 2.8678 -6.5009]\n",
      " [ 3.1275 -6.6595]\n",
      " [ 2.8888 -6.1328]\n",
      " [ 2.863  -5.6339]\n",
      " [ 3.3123 -6.194 ]\n",
      " [ 2.924  -5.8352]\n",
      " [ 3.2008 -5.7126]\n",
      " [ 2.9681 -5.7548]\n",
      " [ 2.2955 -5.4563]\n",
      " [ 3.2082 -5.4202]\n",
      " [ 3.1552 -5.2835]\n",
      " [ 3.0034 -5.1757]\n",
      " [ 3.0423 -5.4526]\n",
      " [ 2.949  -5.6894]\n",
      " [ 2.8715 -5.634 ]\n",
      " [ 2.8785 -5.1246]\n",
      " [ 2.9229 -5.1173]\n",
      " [ 3.1013 -5.7328]\n",
      " [ 2.8637 -6.1347]\n",
      " [ 2.9142 -6.4147]\n",
      " [ 2.8375 -5.208 ]\n",
      " [ 2.6443 -5.3919]\n",
      " [ 2.8861 -5.9215]\n",
      " [ 2.8375 -5.208 ]\n",
      " [ 2.5295 -4.8345]\n",
      " [ 2.921  -5.5508]\n",
      " [ 2.7412 -5.5858]\n",
      " [ 2.6591 -4.3819]\n",
      " [ 2.513  -4.9804]\n",
      " [ 3.1058 -5.5106]\n",
      " [ 3.3025 -5.7574]\n",
      " [ 2.7957 -5.072 ]\n",
      " [ 2.9738 -5.8251]\n",
      " [ 2.671  -5.0941]\n",
      " [ 2.9687 -5.901 ]\n",
      " [ 2.8074 -5.4297]\n",
      " [ 6.7961 -6.0002]\n",
      " [ 6.4438 -5.6339]\n",
      " [ 6.9754 -5.8189]\n",
      " [ 5.6923 -4.4891]\n",
      " [ 6.5985 -5.3901]\n",
      " [ 6.1518 -4.8974]\n",
      " [ 6.6066 -5.5986]\n",
      " [ 4.7599 -4.3136]\n",
      " [ 6.5546 -5.5437]\n",
      " [ 5.5012 -4.5941]\n",
      " [ 5.0003 -4.0522]\n",
      " [ 6.0224 -5.2124]\n",
      " [ 5.7737 -4.7668]\n",
      " [ 6.4954 -5.1904]\n",
      " [ 5.3365 -5.0629]\n",
      " [ 6.4389 -5.783 ]\n",
      " [ 6.1709 -4.9627]\n",
      " [ 5.7459 -4.9828]\n",
      " [ 6.4537 -4.7729]\n",
      " [ 5.5546 -4.7332]\n",
      " [ 6.6276 -5.2305]\n",
      " [ 5.8681 -5.2479]\n",
      " [ 6.8078 -4.9872]\n",
      " [ 6.4318 -5.1323]\n",
      " [ 6.2254 -5.4651]\n",
      " [ 6.411  -5.6443]\n",
      " [ 6.8424 -5.5594]\n",
      " [ 7.0687 -5.5821]\n",
      " [ 6.3238 -5.1524]\n",
      " [ 5.204  -4.9496]\n",
      " [ 5.441  -4.6122]\n",
      " [ 5.3195 -4.6372]\n",
      " [ 5.6463 -5.003 ]\n",
      " [ 6.8901 -4.8935]\n",
      " [ 6.0986 -4.8314]\n",
      " [ 6.3185 -5.5098]\n",
      " [ 6.7318 -5.7228]\n",
      " [ 6.3242 -4.944 ]\n",
      " [ 5.7565 -5.048 ]\n",
      " [ 5.6759 -4.6351]\n",
      " [ 5.9744 -4.6452]\n",
      " [ 6.4015 -5.2809]\n",
      " [ 5.7402 -4.9125]\n",
      " [ 4.8043 -4.3063]\n",
      " [ 5.8669 -4.8115]\n",
      " [ 5.8425 -5.1035]\n",
      " [ 5.8866 -5.0231]\n",
      " [ 6.153  -5.3338]\n",
      " [ 4.6029 -4.5632]\n",
      " [ 5.8092 -4.9677]\n",
      " [ 8.0431 -5.3029]\n",
      " [ 6.9254 -4.7398]\n",
      " [ 8.1278 -5.6567]\n",
      " [ 7.4822 -5.1336]\n",
      " [ 7.8611 -5.2728]\n",
      " [ 8.9082 -5.8619]\n",
      " [ 6.0307 -4.1234]\n",
      " [ 8.4433 -5.6671]\n",
      " [ 7.831  -5.0692]\n",
      " [ 8.4295 -6.0951]\n",
      " [ 7.1733 -5.5568]\n",
      " [ 7.3137 -5.0986]\n",
      " [ 7.6767 -5.53  ]\n",
      " [ 6.8559 -4.5383]\n",
      " [ 7.0966 -4.7754]\n",
      " [ 7.4161 -5.4335]\n",
      " [ 7.4606 -5.3555]\n",
      " [ 9.0001 -6.4863]\n",
      " [ 9.306  -5.568 ]\n",
      " [ 6.8097 -4.5537]\n",
      " [ 7.9395 -5.6915]\n",
      " [ 6.7094 -4.7091]\n",
      " [ 9.0106 -5.7715]\n",
      " [ 6.899  -5.1107]\n",
      " [ 7.7872 -5.6481]\n",
      " [ 8.1255 -5.8731]\n",
      " [ 6.769  -5.1356]\n",
      " [ 6.802  -5.1983]\n",
      " [ 7.6342 -5.1039]\n",
      " [ 7.8989 -5.7772]\n",
      " [ 8.3523 -5.6875]\n",
      " [ 8.7437 -6.6852]\n",
      " [ 7.6701 -5.0964]\n",
      " [ 6.9544 -5.1709]\n",
      " [ 7.291  -4.8133]\n",
      " [ 8.5879 -6.0005]\n",
      " [ 7.6563 -5.4536]\n",
      " [ 7.4162 -5.3628]\n",
      " [ 6.6802 -5.1502]\n",
      " [ 7.619  -5.6862]\n",
      " [ 7.8256 -5.4973]\n",
      " [ 7.4338 -5.724 ]\n",
      " [ 6.9254 -4.7398]\n",
      " [ 8.0747 -5.5907]\n",
      " [ 7.9307 -5.6182]\n",
      " [ 7.4554 -5.5021]\n",
      " [ 7.037  -4.9397]\n",
      " [ 7.2754 -5.3932]\n",
      " [ 7.413  -5.4306]\n",
      " [ 6.901  -5.0318]]\n"
     ]
    }
   ],
   "source": [
    "print_answer('1i)', iris_features.dot(eigenvectors[:, :2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Implemente o algoritmo do k-means na linguagem de programação de sua preferência e inicializeeste algoritmo com k=3 centros c1=[5.1,3.5,1.4,0.2], c2=[4.9,3.0,1.4,0.2], c3=[4.7,3.2,1.3,0.2].\n",
    "<br />\n",
    "    a) Após a convergência, qual o valor dos centros?\n",
    "    <br />\n",
    "    b) Qual o centro mais próximo do centro da classe “Iris-setosa”\n",
    "    <br />\n",
    "    c) Qual o centro mais próximo do centro da classe “Iris-versicolor”\n",
    "    <br />\n",
    "    d) Qual o centro mais próximo do centro da classe “Iris-virginica”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resposta 2a):\n",
      "[[6.8538 3.0769 5.7154 2.0538]\n",
      " [5.8836 2.741  4.3885 1.4344]\n",
      " [5.006  3.418  1.464  0.244 ]]\n",
      "Resposta 2b):\n",
      "2\n",
      "Resposta 2c):\n",
      "1\n",
      "Resposta 2d):\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "def dist(a, b):\n",
    "    return np.linalg.norm(np.array(a) - np.array(b), axis=1)\n",
    "\n",
    "def kmeans(matrix, k, centroids):\n",
    "    current_centroids = np.array(centroids)\n",
    "    previous_centroids = np.zeros(current_centroids.shape)\n",
    "\n",
    "    error = dist(current_centroids, previous_centroids)\n",
    "    nearest_clusters = np.zeros(len(matrix))\n",
    "    \n",
    "    while sum(error) != 0:\n",
    "        for i in range(len(matrix)):\n",
    "            distances = dist(matrix[i], current_centroids)\n",
    "            nearest_clusters[i] = np.argmin(distances)\n",
    "\n",
    "            previous_centroids = current_centroids.copy()\n",
    "\n",
    "        for i in range(k):\n",
    "            current_centroids[i] = np.mean(matrix[np.where(nearest_clusters == i)], axis=0)\n",
    "\n",
    "        error = dist(current_centroids, previous_centroids)\n",
    "    return (nearest_clusters, current_centroids)\n",
    "\n",
    "def get_center(features, target):\n",
    "    target_set = set(target)\n",
    "    return np.array([np.mean(features[np.where(target == i)], 0) for i in range(len(target_set))])\n",
    "\n",
    "center1 = [5.1, 3.5, 1.4, 0.2]\n",
    "center2 = [4.9, 3.0, 1.4, 0.2]\n",
    "center3 = [4.7, 3.2, 1.3, 0.2]\n",
    "\n",
    "closest_cluster, kmeans_centers = kmeans(iris_features, 3, [center1, center2, center3])\n",
    "\n",
    "centers = get_center(iris_features, iris_target)\n",
    "\n",
    "print_answer('2a)', kmeans_centers)\n",
    "\n",
    "print_answer('2b)', np.argmin(dist(centers[0], kmeans_centers)))\n",
    "print_answer('2c)', np.argmin(dist(centers[1], kmeans_centers)))\n",
    "print_answer('2d)', np.argmin(dist(centers[2], kmeans_centers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 11.33%\n"
     ]
    }
   ],
   "source": [
    "kmeans_class = closest_cluster.copy()\n",
    "kmeans_class[np.where(closest_cluster == 2)] = 0\n",
    "kmeans_class[np.where(closest_cluster == 1)] = 1\n",
    "kmeans_class[np.where(closest_cluster == 0)] = 2\n",
    "\n",
    "error = sum([1 if iris_target[i] != kmeans_class[i] else 0 for i in range(len(iris_target))])/len(iris_target)\n",
    "\n",
    "print(f'Error: {error*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Implemente o algoritmo do KNN na linguagem de programação de sua preferência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def get_neighbors(matrix, element, k):\n",
    "    dist = lambda a, b: np.linalg.norm(a-b, axis=0)\n",
    "    near_elements = []\n",
    "    \n",
    "    for i, other_element in enumerate(matrix):\n",
    "        distance = dist(element[0:-1], other_element[0:-1])\n",
    "        near_elements.append((other_element[-1], distance))\n",
    "    \n",
    "    near_elements.sort(key = lambda x: x[1])\n",
    "    \n",
    "    # return distances removing 1st element that is the element itself\n",
    "    return np.array([near_elements[i][0] for i in range(1, k+1)])\n",
    "\n",
    "def class_from_neighbors(neighbors):\n",
    "    return max(collections.Counter(neighbors))\n",
    "\n",
    "def knn(train, test, k):\n",
    "    classes = []\n",
    "    correct = 0\n",
    "    for i, element in enumerate(test):\n",
    "        neighbors = get_neighbors(train, element, k)\n",
    "        class_ = class_from_neighbors(neighbors)\n",
    "        classes.append(class_)\n",
    "        # print(f'> Prediction = {class_}, Actual = {element[-1]}')\n",
    "        \n",
    "        if class_ == element[-1]: correct += 1\n",
    "    \n",
    "    error = 1 - correct/len(test)\n",
    "    # print(f'Error = {error*100:.2f}%')\n",
    "    return classes, error\n",
    "\n",
    "def train_test_split(matrix, p):\n",
    "    np.random.shuffle(matrix)\n",
    "    train = matrix[0:int(p * len(matrix))]\n",
    "    test = matrix[int(p*len(matrix)) - 1 : -1]\n",
    "    return (train, test)\n",
    "\n",
    "iris = np.column_stack((iris_features, iris_target))\n",
    "train, test = train_test_split(iris, 0.7)\n",
    "\n",
    "_ = knn(train, test, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Implemente um classificador de distância mínima na linguagem de sua preferência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimum_distance(train, test, d):\n",
    "    classes_number = len(set(train[:, -1]))\n",
    "    correct = 0\n",
    "    classes = []\n",
    "    \n",
    "    centroids = np.array([np.mean(train[np.where(train[:, -1] == i)], axis = 0) for i in range(classes_number)])\n",
    "    \n",
    "    for i, element in enumerate(test):\n",
    "        predicted_class = np.argmin(np.array([d(element[0:-1], center[0:-1]) for center in centroids]))\n",
    "        classes.append(predicted_class)\n",
    "        \n",
    "        # print(f'> Prediction = {predicted_class}, Actual = {element[-1]}')\n",
    "        \n",
    "        if predicted_class == element[-1]: correct += 1\n",
    "    \n",
    "    error = 1 - (correct/len(test))\n",
    "    # print(f'Error = {error*100:.2f}%')\n",
    "    return classes, error\n",
    "    \n",
    "euclidean = lambda a, b: np.linalg.norm(a-b)\n",
    "\n",
    "def mahalanobis(a, b):\n",
    "    ab_cov = cov_matrix(np.array([a, b]))\n",
    "    return (a - b).dot(ab_cov).dot((a - b).T)\n",
    "\n",
    "train, test = train_test_split(iris, 0.7)\n",
    "_ = minimum_distance(train, test, mahalanobis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Implemente uma função discriminante utilizando o log da probabilidade a posteriori para cada uma das classes da base de dados Iris."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    $g_i(x) = -\\frac{1}{2}(\\mathbf{x}-\\mathbf{\\mu_i})^T \\mathbf{\\Sigma_i^{-1}}(\\mathbf{x}-\\mathbf{\\mu_i})- \\frac{d}{2}ln(2\\pi)-\\frac{1}{2}ln(\\left | \\mathbf{\\Sigma_i} \\right |) + ln(P(\\omega_i))$\n",
    "    </center>\n",
    "    <br />Simplificando a função discriminante: <br />\n",
    "    <center>\n",
    "    $g_i(x) = (\\mathbf{x}-\\mathbf{\\mu_i})^T \\mathbf{\\Sigma_i^{-1}}(\\mathbf{x}-\\mathbf{\\mu_i}) +ln(\\left | \\mathbf{\\Sigma_i} \\right |) - 2ln(P(\\omega_i))$\n",
    "    </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminant(element, mean, cov, w_i):\n",
    "    inv_cov = np.linalg.inv(cov)\n",
    "    determinant_cov = np.linalg.det(cov)\n",
    "    return (element-mean).dot(inv_cov).dot((element-mean).T) + np.log(determinant_cov) - 2*np.log(w_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Implemente um classificador bayesiano para a base de dados Iris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baysian_classifier(train, test):\n",
    "    classes_number = len(set(train[:, -1]))\n",
    "    result = np.zeros((len(test), classes_number))\n",
    "    \n",
    "    for i in range(classes_number):\n",
    "        selected_train = train[np.where(train[:, -1] == i)]\n",
    "        mean = np.mean(selected_train[:, 0:-1], axis = 0)\n",
    "        cov = cov_matrix(selected_train[:, 0:-1])\n",
    "        w_i = len(selected_train)/len(train)\n",
    "        \n",
    "        for j, element in enumerate(test):\n",
    "            element = element[0:-1]\n",
    "            result[j][i] = discriminant(element, mean, cov, w_i)\n",
    "    \n",
    "    result = np.argmin(result, axis=1)\n",
    "    error = sum([1 if test[i, -1] != result[i] else 0 for i in range(len(test))])/len(test)\n",
    "    # print(f'Error = {error*100:.2f}%')\n",
    "    return result, error\n",
    "\n",
    "train, test = train_test_split(iris, 0.7)\n",
    "result, error = baysian_classifier(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Implemente um classificador bayesiano para a base de dados Iris projetada sobre as duas maiores componentes principais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues, eigenvectors = np.linalg.eig(cov_matrix(iris_features))\n",
    "iris_feat_pca = iris_features.dot(eigenvectors[:, 0:2])\n",
    "iris_pca = np.column_stack((iris_feat_pca, iris_target))\n",
    "\n",
    "train, test = train_test_split(iris_pca, 0.7)\n",
    "result, error = baysian_classifier(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Determine o erro percentual e o desvio padrão do erro(quando for possível) nos conjuntos de treinamento e validação dos classificadores implementados nas questões 3,4, 6 e 7 utilizando os seguintes métodos de particionamento de dados:\n",
    "<br />\n",
    "a) Houldout com 90% das amostras para treinamento e 10% para validação;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Error = 6.67%\n",
      "Minimum Distance Error = 6.67%\n",
      "Baysian Error = 0.00%\n",
      "Baysian PCA Error = 6.67%\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(iris, 0.9)\n",
    "train_pca, test_pca = train_test_split(iris_pca, 0.9)\n",
    "\n",
    "_, knn_error = knn(train, test, 3)\n",
    "_, mind_error = minimum_distance(train, test, euclidean)\n",
    "_, baysian_error = baysian_classifier(train, test)\n",
    "_, baysian_pca_error = baysian_classifier(train_pca, test_pca)\n",
    "\n",
    "print(f'KNN Error = {knn_error*100:.2f}%')\n",
    "print(f'Minimum Distance Error = {mind_error*100:.2f}%')\n",
    "print(f'Baysian Error = {baysian_error*100:.2f}%')\n",
    "print(f'Baysian PCA Error = {baysian_pca_error*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Cross-Validation 10-folds;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Error = (0.05333333333333332, 0.04988876515698588)\n",
      "Minimum Distance Error = (0.07999999999999999, 0.08326663997864532)\n",
      "Baysian Error = (0.026666666666666665, 0.03265986323710904)\n",
      "Baysian PCA Error = (0.026666666666666665, 0.044221663871405324)\n"
     ]
    }
   ],
   "source": [
    "def kfolds_split(matrix, k):\n",
    "    np.random.shuffle(matrix)\n",
    "    folds = []\n",
    "    \n",
    "    for i in range(k):\n",
    "        lowerbound = int((len(matrix)/k) * i)\n",
    "        upperbound = int((len(matrix)/k) * (i+1))\n",
    "        folds.append(matrix[lowerbound:upperbound,:])\n",
    "    \n",
    "    return folds\n",
    "\n",
    "def kfolds_validation(matrix, k, validation):\n",
    "    folds = kfolds_split(matrix, k)\n",
    "    error = []\n",
    "    \n",
    "    for i in range(k):\n",
    "        folds_copy = folds.copy()\n",
    "        test = folds_copy.pop(i)\n",
    "        train = np.row_stack(folds_copy)\n",
    "        \n",
    "        if validation == 0:\n",
    "            error = np.append(error, knn(train, test, 3)[1])\n",
    "        elif validation == 1:\n",
    "            error = np.append(error, [minimum_distance(train, test, euclidean)[1]])\n",
    "        elif validation == 2:\n",
    "            error = np.append(error, [baysian_classifier(train, test)[1]])\n",
    "    return np.mean(error), np.std(error)\n",
    "\n",
    "\n",
    "print(f'KNN Error = {kfolds_validation(iris, 10, 0)}')\n",
    "print(f'Minimum Distance Error = {kfolds_validation(iris, 10, 1)}')\n",
    "print(f'Baysian Error = {kfolds_validation(iris, 10, 2)}')\n",
    "print(f'Baysian PCA Error = {kfolds_validation(iris_pca, 10, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Monte Carlo Cross-Validation com 90% das amostras para treinamento e 10% para validação;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Error = (0.05466666666666665, 0.03021241670996861)\n",
      "Minimum Distance Error = (0.08133333333333331, 0.06638607618402453)\n",
      "Baysian Error = (0.034, 0.04054626986542658)\n",
      "Baysian PCA Error = (0.034, 0.04054626986542658)\n"
     ]
    }
   ],
   "source": [
    "def monte_carlo_cv(matrix, p, k, validation):\n",
    "    error = np.array([])\n",
    "    for i in range(k):\n",
    "        train, test = train_test_split(iris_pca, p) \n",
    "        \n",
    "        if validation == 0:\n",
    "            error = np.append(error, knn(train, test, 3)[1])\n",
    "        elif validation == 1:\n",
    "            error = np.append(error, [minimum_distance(train, test, euclidean)[1]])\n",
    "        elif validation == 2:\n",
    "            error = np.append(error, [baysian_classifier(train, test)[1]])\n",
    "    return np.mean(error), np.std(error)\n",
    "\n",
    "print(f'KNN Error = {monte_carlo_cv(iris, 0.7, 100, 0)}')\n",
    "print(f'Minimum Distance Error = {monte_carlo_cv(iris, 0.9, 100, 1)}')\n",
    "print(f'Baysian Error = {monte_carlo_cv(iris, 0.9, 100, 2)}')\n",
    "print(f'Baysian PCA Error = {monte_carlo_cv(iris_pca, 0.9, 100, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) Repita as avaliações da questão 6, calculando a matriz de confusão do erro percentual para cada um dos métodos de particionamento (Houldout, Cross-Validation 10-folds, Monte Carlo Cross-Validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Confusion Matrix\n",
      "[[20.      0.      0.    ]\n",
      " [ 0.     33.3333  0.    ]\n",
      " [ 0.      6.6667 40.    ]]\n",
      "\n",
      "Minimum Confusion Matrix\n",
      "[[20.      0.      0.    ]\n",
      " [ 0.     33.3333  0.    ]\n",
      " [ 0.     13.3333 33.3333]]\n",
      "\n",
      "Baysian Confusion Matrix\n",
      "[[20.      0.      0.    ]\n",
      " [ 0.     33.3333  0.    ]\n",
      " [ 0.      0.     46.6667]]\n",
      "\n",
      "Baysian  PCA Confusion Matrix\n",
      "[[46.6667  0.      0.    ]\n",
      " [ 0.     20.      0.    ]\n",
      " [ 0.      0.     33.3333]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def confusion_matrix(predicted, actual):\n",
    "    conf_shape = len(set(actual))\n",
    "    conf = np.zeros((conf_shape, conf_shape))\n",
    "    for pred, act in zip(predicted, actual):\n",
    "        conf[int(act), int(pred)] += 1\n",
    "    return conf/conf.sum() * 100\n",
    "    \n",
    "train, test = train_test_split(iris, 0.9)\n",
    "train_pca, test_pca = train_test_split(iris_pca, 0.9)\n",
    "test_labels = test[:, -1]\n",
    "test_pca_labels = test_pca[:, -1]\n",
    "\n",
    "knn_predicted, _ = knn(train, test, 3)\n",
    "mind_predicted, _ = minimum_distance(train, test, euclidean)\n",
    "baysian_predicted, _ = baysian_classifier(train, test)\n",
    "baysian_pca_predicted, _ = baysian_classifier(train_pca, test_pca)\n",
    "\n",
    "print(f'KNN Confusion Matrix\\n{confusion_matrix(knn_predicted, test_labels)}\\n')\n",
    "print(f'Minimum Confusion Matrix\\n{confusion_matrix(mind_predicted, test_labels)}\\n')\n",
    "print(f'Baysian Confusion Matrix\\n{confusion_matrix(baysian_predicted, test_labels)}\\n')\n",
    "print(f'Baysian  PCA Confusion Matrix\\n{confusion_matrix(baysian_pca_predicted, test_pca_labels)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://onlinecourses.science.psu.edu/stat505/node/94/\n",
    "# https://people.revoledu.com/kardi/tutorial/LDA/Numerical%20Example.html\n",
    "\n",
    "def linear_discriminant(matrix, test):\n",
    "    matrix_features = matrix[:,0:-1]\n",
    "    columns_num = matrix_features.shape[1]\n",
    "    classes = set(matrix[:,-1])\n",
    "    pooled_covariance = np.zeros((columns_num, columns_num))\n",
    "    \n",
    "    for class_ in classes:\n",
    "        matrix_class = matrix_features[np.where(matrix[:, -1] == class_)]\n",
    "        p = len(matrix_class)/len(matrix)\n",
    "        corrected_data = matrix_class - np.mean(matrix_features, axis=0)\n",
    "        pooled_covariance += corrected_data.T.dot(corrected_data) / (len(corrected_data) - 1)\n",
    "        \n",
    "    pc_inv = np.linalg.inv(pooled_covariance)\n",
    "    classification = []\n",
    "    correct = 0\n",
    "    \n",
    "    for i, element in enumerate(test):\n",
    "        discriminants = []\n",
    "        for class_ in classes:\n",
    "            matrix_class = matrix_features[np.where(matrix[:, -1] == class_)]\n",
    "            class_mean = np.mean(matrix_class, axis=0)\n",
    "            \n",
    "            element_features = element[0:-1]\n",
    "            \n",
    "            p = len(matrix_class)/len(matrix)\n",
    "            \n",
    "            f_i = class_mean.dot(pc_inv).dot(element_features.T) - 0.5*class_mean.dot(pc_inv).dot(class_mean.T) + np.log(p)\n",
    "            discriminants.append(f_i)\n",
    "        classification.append(np.argmax(discriminants))\n",
    "        \n",
    "        if classification[i] == element[-1]: correct += 1\n",
    "        print(f'> Prediction = {classification[i]}, Actual = {element[-1]}')\n",
    "        \n",
    "    print(f'Error = {(1 - correct/len(test))*100:.2f}%')\n",
    "    \n",
    "    return classification\n",
    "        \n",
    "# train, test = train_test_split(iris, 0.7)\n",
    "# _ = linear_discriminant(train, test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
