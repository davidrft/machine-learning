{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load('iris.data');\n",
    "iris_features = iris(:,1:end-1);\n",
    "iris_classes = iris(:,end);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    \n",
    "# Aprendizagem de Máquina (ES456/2018-2)\n",
    "## Lista de exercícios 2\n",
    "### 2018-11-20\n",
    "    \n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Utilizando a base de dados Iris, disponível no link abaixo, sem preprocessamento e a linguagem de programação de sua preferência, implemente e avalie o desempenho dos seguintes classificadores:\n",
    "<br />\n",
    "<br />\n",
    "a) Perceptron (4 entradas e 3 saídas, função de ativação tipo sigmóide)\n",
    "<br />\n",
    "b) Perceptron (4 entradas e 3 saídas, função de ativação tipo ReLu)\n",
    "<br />\n",
    "c) MLP (4 entradas, 10 nodos na camada intermediária e 3 na camada de saída, função de ativação do sigmóide)\n",
    "<br />\n",
    "d) MLP (4 entradas, 10 nodos na camada intermediária e 3 na camada de saída, função de ativação tipo ReLu)\n",
    "<br />\n",
    "<br />\n",
    "OBS: Utilize o gradiente descendente estocástico como método de treinamento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para a função de ativação do tipo sigmoide:\n",
    "$$f(z) = \\frac{1}{1 + e^{-z}}$$\n",
    "\n",
    "Analisando a função, vê-se que $f(z) \\geq 0.5$ quando $z \\geq 0$ e $f(z) < 0.5$ quando $z < 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "function s = sigmoid(z)\n",
    "    s = 1 ./ (1 + e.^(-z));\n",
    "endfunction\n",
    "\n",
    "function r = relu(z)\n",
    "    r = max(0, z);\n",
    "endfunction\n",
    "\n",
    "function p = predict(features, weights, activation)\n",
    "    features = [ones(size(features, 1), 1) features];\n",
    "    activation_arg = features * weights';\n",
    "    p = activation(activation_arg);\n",
    "endfunction\n",
    "\n",
    "function a = add_one_columns(matrix)\n",
    "    a = [ones(size(matrix, 1), 1) matrix];\n",
    "endfunction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$J(W) = \\frac{1}{2m} \\sum_{i = 1}^{m}(p(x^{(i)}) - y^{(i)})^2$$\n",
    "$$w_j := w_j - \\alpha \\frac{\\delta J}{\\delta w_j} = w_j - \\frac{\\alpha}{m} \\sum_{i = 1}^{m}(p(x^{(i)}) - y^{(i)})x_{j}^{(i)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "function weights = train(train, learning_rate, n, activation)\n",
    "    m = length(train);\n",
    "    unq_tc = unique(train(:,end))';\n",
    "    train_features = train(:,1:end-1);\n",
    "    tf_one_column = add_one_columns(train_features);\n",
    "    \n",
    "    weights = zeros(length(unq_tc), size(train, 2));\n",
    "    \n",
    "    if (numel(unq_tc) == 2) \n",
    "        unq_tc = [unq_tc(1)];\n",
    "    endif\n",
    "    \n",
    "    for i = unq_tc\n",
    "        train_mv = train;\n",
    "        train_mv(:,end) = train_mv(:,end) == i;\n",
    "        train_mv_classes = train_mv(:,end);\n",
    "            \n",
    "        for j = 1:n    \n",
    "            p = predict(train_features, weights(i+1,:), activation);\n",
    "            dJ = (p - train_mv_classes)' *  tf_one_column;\n",
    "            weights(i+1,:) = weights(i+1,:) - ((learning_rate/m) * dJ);\n",
    "        endfor\n",
    "        \n",
    "    endfor\n",
    "endfunction\n",
    "\n",
    "function [train, test] = train_test_split(dataframe, p)\n",
    "    % Mistura-se as linhas\n",
    "    m = size(dataframe, 1);\n",
    "    idx = randperm(m);\n",
    "    dataframe = dataframe(idx,:);\n",
    "\n",
    "    % Calcula-se o numero de elementos no conjunto de treinamento\n",
    "    train_off = round(size(dataframe, 1) * p);\n",
    "\n",
    "    % Separa-se os dados\n",
    "    train = dataframe(1:train_off,:);\n",
    "    test = dataframe(train_off+1:end,:);\n",
    "endfunction\n",
    "\n",
    "dataset = iris;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1a)\n",
      "weights =\n",
      "\n",
      "   0.254040   0.432980   1.199844  -1.901812  -0.863620\n",
      "   0.083797  -0.096556  -0.794910   0.516812  -0.047343\n",
      "  -0.485161  -0.909356  -0.964626   1.500086   0.925896\n",
      "\n",
      "Taxa de erro: 0.05\n",
      "Taxa de erro: 0.05\n"
     ]
    }
   ],
   "source": [
    "disp(\"1a)\")\n",
    "\n",
    "% Separa-se os dados\n",
    "[train_data, test] = train_test_split(dataset, 0.6);\n",
    "test_features = add_one_columns(test(:,1:end-1));\n",
    "test_classes = test(:,end);\n",
    "\n",
    "% Calcula-se os pesos usando sigmoide\n",
    "weights = train(test, 0.02, 1000, @sigmoid)\n",
    "activ_arg = test_features * weights';\n",
    "\n",
    "% Passa-se por um selecionador de máximo\n",
    "[a p] = max(sigmoid(activ_arg), [], 2);\n",
    "\n",
    "% Calcula-se o erro\n",
    "err = sum((p-1) - test_classes != 0) / sum(numel(test_classes));\n",
    "printf(\"Taxa de erro: %.2f\", err);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1b)\n",
      "weights =\n",
      "\n",
      "   0.11148   0.13945   0.19990  -0.31837  -0.20003\n",
      "   0.23882   0.16791  -0.29664   0.10058  -0.31719\n",
      "  -0.16646  -0.27521  -0.32668   0.52246   0.46991\n",
      "\n",
      "Taxa de erro: 0.05\n",
      "Taxa de erro: 0.05\n"
     ]
    }
   ],
   "source": [
    "disp(\"1b)\")\n",
    "\n",
    "% Separa-se os dados\n",
    "[train_data, test] = train_test_split(dataset, 0.6);\n",
    "test_features = add_one_columns(test(:,1:end-1));\n",
    "test_classes = test(:,end);\n",
    "\n",
    "% Calcula-se os pesos usando ReLU\n",
    "weights = train(train_data, 0.02, 1000, @relu)\n",
    "activ_arg = test_features * weights';\n",
    "\n",
    "% Passa-se por um selecionador de máximo\n",
    "[a p] = max(relu(activ_arg), [], 2);\n",
    "\n",
    "% Calcula-se o erro\n",
    "err = sum((p-1) - test_classes != 0) / sum(numel(test_classes));\n",
    "printf(\"Taxa de erro: %.2f\", err);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 'iris_features' undefined near line 1 column 41\n",
      "error: 'weights1' undefined near line 1 column 37\n",
      "error: 'iris' undefined near line 1 column 20\n",
      "error: 'iris_features' undefined near line 1 column 41\n"
     ]
    }
   ],
   "source": [
    "function [weights1, weights2] = train_mlp(data, weights1, weights2, alpha=0.01, n)\n",
    "    m = length(data);\n",
    "    train_features = data(:,1:end-1);\n",
    "    train_classes = zeros(m, rows(weights2));\n",
    "    \n",
    "    train_classes(:,1) = data(:,end) == 0;\n",
    "    train_classes(:,2) = data(:,end) == 1;\n",
    "    train_classes(:,3) = data(:,end) == 2;\n",
    "    \n",
    "    tf_one_column = add_one_columns(train_features);\n",
    "    \n",
    "    % LEARN\n",
    "    for i=1:n\n",
    "        activation1 = tf_one_column * weights1';\n",
    "        activation2 = add_one_columns((activation1));\n",
    "    \n",
    "        predicted = sigmoid(activation2 * weights2');\n",
    "    \n",
    "        delta2 = (predicted - train_classes);\n",
    "        delta1 = (delta2 * weights2);\n",
    "        \n",
    "        dJ2 = delta2' * activation2;\n",
    "        weights2 = weights2 - (alpha/m)*dJ2;\n",
    "        \n",
    "        dJ1 = (delta1' * tf_one_column)(2:end,:); % removendo o bias\n",
    "        weights1 = weights1 - (alpha/m)*dJ1; \n",
    "    endfor\n",
    "endfunction\n",
    "\n",
    "hidden_layers = 10;\n",
    "weights1 = zeros(hidden_layers, columns(iris_features) + 1);\n",
    "\n",
    "final_layers = 3;\n",
    "weights2 = zeros(final_layers, rows(weights1) + 1);\n",
    "\n",
    "[w1, w2] = train_mlp(iris, weights1, weights2, 0.01, 500)\n",
    "\n",
    "add_one_columns(sigmoid(add_one_columns(iris_features)*w1'))*w2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Repita as avaliações anteriores removendo o valor médio da base de dados Iris e normalizando os dados pelo desvio padrão de cada característica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Implemente o algoritmo de Kohonen com um mapa de 4x4 nodos, realize uma categorização sobre conjunto de dados Iris e plote o mapa atribuindo uma cor para cada nodo para categoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) Implemente uma rede RBF com bases centradas nos nodos do SOM, da questão anterior e avalie o desempenho de classificação o dataset do Iris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Utilize um ADALINE para detectar a sequência binária 1101 em um canal com ruído gaussiano aditivo de $0.1$; O dataset para treinamento e teste é:\n",
    "<br />\n",
    "“010011011000111011100010011002002201110011003001100.500011001000011110001111”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Utilize uma MLP com memória para realizar a mesma detecção anterior, avalie e compare com do ADALINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://github.com/calysto/metakernel/blob/master/metakernel/magics/README.md"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "4.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
